{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXwjiPOBwdnLflLWRcm7+i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gustavo-hen/gsi073/blob/main/Regressao_logistica_alteradogpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csrNt0NrWdG0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Carregar dados\n",
        "iris = sklearn.datasets.load_iris()\n",
        "X = iris.data        # 4 features: sépalas e pétalas\n",
        "y = (iris.target == 1).astype(float)  # 1 se Versicolor, 0 caso contrário\n",
        "\n",
        "# 2. Dividir os dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Preparar os dados para PyTorch\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Definir modelo: regressão logística\n",
        "modelo = torch.nn.Linear(4, 1)  # 4 features → 1 saída (probabilidade de ser Versicolor)\n",
        "\n",
        "# 5. Definir função de perda e algoritmo de otimização\n",
        "funcao_perda = torch.nn.BCEWithLogitsLoss()  # combinação de sigmoid + BCE\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "SFlIPB7zZwwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Treinamento\n",
        "for epoch in range(1000):\n",
        "    modelo.train()  # Define o modelo para modo de treinamento\n",
        "\n",
        "    optimizer.zero_grad()  # Zera os gradientes\n",
        "    outputs = modelo(X_train)  # Faz a previsão para os dados de treino\n",
        "    loss = funcao_perda(outputs, y_train)  # Calcula a perda\n",
        "    loss.backward()  # Calcula os gradientes\n",
        "    optimizer.step()  # Atualiza os pesos do modelo\n",
        "\n",
        "    # A cada 10 épocas, exibe o valor da perda no conjunto de treino\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Época [{epoch+1}/1000], Loss (treinamento): {loss.item():.4f}\")\n",
        "\n",
        "    # Avaliar no conjunto de teste a cada 100 épocas\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        modelo.eval()  # Muda para o modo de avaliação\n",
        "        with torch.no_grad():  # Desliga o cálculo de gradientes (não precisa para validação)\n",
        "            outputs_test = modelo(X_test)  # Faz a previsão no conjunto de teste\n",
        "            # Aplica o sigmoid para converter a saída em probabilidade\n",
        "            y_pred = torch.sigmoid(outputs_test)\n",
        "            y_pred = y_pred.round()  # Converte as probabilidades em 0 ou 1\n",
        "\n",
        "            # Calcula a acurácia\n",
        "            accuracy = (y_pred.eq(y_test).sum().item()) / y_test.size(0)\n",
        "            print(f\"Época [{epoch+1}/1000], Acurácia (teste): {accuracy*100:.2f}%\")\n",
        "\n",
        "\n",
        "# 8. Gerar gráficos\n",
        "epochs = range(10, 1001, 10)  # épocas em que a perda foi registrada\n",
        "\n",
        "# Plotando o gráfico de Loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)  # Plot 1: Loss\n",
        "plt.plot(epochs, losses, marker='o', color='b', label='Loss (treinamento)')\n",
        "plt.title('Evolução da Loss durante o Treinamento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Plotando o gráfico de Acurácia\n",
        "plt.subplot(1, 2, 2)  # Plot 2: Acurácia\n",
        "plt.plot(epochs, acuracias, marker='o', color='g', label='Acurácia (teste)')\n",
        "plt.title('Evolução da Acurácia durante o Treinamento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Exibe os gráficos\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RkzwpI2RZ8ry",
        "outputId": "7c910342-81cb-4a72-ad78-fb39063ceb2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época [10/1000], Loss (treinamento): 0.5213\n",
            "Época [20/1000], Loss (treinamento): 0.5211\n",
            "Época [30/1000], Loss (treinamento): 0.5210\n",
            "Época [40/1000], Loss (treinamento): 0.5209\n",
            "Época [50/1000], Loss (treinamento): 0.5207\n",
            "Época [60/1000], Loss (treinamento): 0.5206\n",
            "Época [70/1000], Loss (treinamento): 0.5205\n",
            "Época [80/1000], Loss (treinamento): 0.5204\n",
            "Época [90/1000], Loss (treinamento): 0.5202\n",
            "Época [100/1000], Loss (treinamento): 0.5201\n",
            "Época [100/1000], Acurácia (teste): 76.67%\n",
            "Época [110/1000], Loss (treinamento): 0.5200\n",
            "Época [120/1000], Loss (treinamento): 0.5199\n",
            "Época [130/1000], Loss (treinamento): 0.5198\n",
            "Época [140/1000], Loss (treinamento): 0.5197\n",
            "Época [150/1000], Loss (treinamento): 0.5195\n",
            "Época [160/1000], Loss (treinamento): 0.5194\n",
            "Época [170/1000], Loss (treinamento): 0.5193\n",
            "Época [180/1000], Loss (treinamento): 0.5192\n",
            "Época [190/1000], Loss (treinamento): 0.5191\n",
            "Época [200/1000], Loss (treinamento): 0.5190\n",
            "Época [200/1000], Acurácia (teste): 76.67%\n",
            "Época [210/1000], Loss (treinamento): 0.5189\n",
            "Época [220/1000], Loss (treinamento): 0.5188\n",
            "Época [230/1000], Loss (treinamento): 0.5187\n",
            "Época [240/1000], Loss (treinamento): 0.5186\n",
            "Época [250/1000], Loss (treinamento): 0.5185\n",
            "Época [260/1000], Loss (treinamento): 0.5184\n",
            "Época [270/1000], Loss (treinamento): 0.5183\n",
            "Época [280/1000], Loss (treinamento): 0.5182\n",
            "Época [290/1000], Loss (treinamento): 0.5181\n",
            "Época [300/1000], Loss (treinamento): 0.5180\n",
            "Época [300/1000], Acurácia (teste): 76.67%\n",
            "Época [310/1000], Loss (treinamento): 0.5179\n",
            "Época [320/1000], Loss (treinamento): 0.5178\n",
            "Época [330/1000], Loss (treinamento): 0.5177\n",
            "Época [340/1000], Loss (treinamento): 0.5176\n",
            "Época [350/1000], Loss (treinamento): 0.5175\n",
            "Época [360/1000], Loss (treinamento): 0.5174\n",
            "Época [370/1000], Loss (treinamento): 0.5173\n",
            "Época [380/1000], Loss (treinamento): 0.5172\n",
            "Época [390/1000], Loss (treinamento): 0.5171\n",
            "Época [400/1000], Loss (treinamento): 0.5170\n",
            "Época [400/1000], Acurácia (teste): 76.67%\n",
            "Época [410/1000], Loss (treinamento): 0.5170\n",
            "Época [420/1000], Loss (treinamento): 0.5169\n",
            "Época [430/1000], Loss (treinamento): 0.5168\n",
            "Época [440/1000], Loss (treinamento): 0.5167\n",
            "Época [450/1000], Loss (treinamento): 0.5166\n",
            "Época [460/1000], Loss (treinamento): 0.5165\n",
            "Época [470/1000], Loss (treinamento): 0.5164\n",
            "Época [480/1000], Loss (treinamento): 0.5164\n",
            "Época [490/1000], Loss (treinamento): 0.5163\n",
            "Época [500/1000], Loss (treinamento): 0.5162\n",
            "Época [500/1000], Acurácia (teste): 76.67%\n",
            "Época [510/1000], Loss (treinamento): 0.5161\n",
            "Época [520/1000], Loss (treinamento): 0.5160\n",
            "Época [530/1000], Loss (treinamento): 0.5159\n",
            "Época [540/1000], Loss (treinamento): 0.5159\n",
            "Época [550/1000], Loss (treinamento): 0.5158\n",
            "Época [560/1000], Loss (treinamento): 0.5157\n",
            "Época [570/1000], Loss (treinamento): 0.5156\n",
            "Época [580/1000], Loss (treinamento): 0.5156\n",
            "Época [590/1000], Loss (treinamento): 0.5155\n",
            "Época [600/1000], Loss (treinamento): 0.5154\n",
            "Época [600/1000], Acurácia (teste): 76.67%\n",
            "Época [610/1000], Loss (treinamento): 0.5153\n",
            "Época [620/1000], Loss (treinamento): 0.5152\n",
            "Época [630/1000], Loss (treinamento): 0.5152\n",
            "Época [640/1000], Loss (treinamento): 0.5151\n",
            "Época [650/1000], Loss (treinamento): 0.5150\n",
            "Época [660/1000], Loss (treinamento): 0.5149\n",
            "Época [670/1000], Loss (treinamento): 0.5149\n",
            "Época [680/1000], Loss (treinamento): 0.5148\n",
            "Época [690/1000], Loss (treinamento): 0.5147\n",
            "Época [700/1000], Loss (treinamento): 0.5147\n",
            "Época [700/1000], Acurácia (teste): 76.67%\n",
            "Época [710/1000], Loss (treinamento): 0.5146\n",
            "Época [720/1000], Loss (treinamento): 0.5145\n",
            "Época [730/1000], Loss (treinamento): 0.5144\n",
            "Época [740/1000], Loss (treinamento): 0.5144\n",
            "Época [750/1000], Loss (treinamento): 0.5143\n",
            "Época [760/1000], Loss (treinamento): 0.5142\n",
            "Época [770/1000], Loss (treinamento): 0.5142\n",
            "Época [780/1000], Loss (treinamento): 0.5141\n",
            "Época [790/1000], Loss (treinamento): 0.5140\n",
            "Época [800/1000], Loss (treinamento): 0.5140\n",
            "Época [800/1000], Acurácia (teste): 76.67%\n",
            "Época [810/1000], Loss (treinamento): 0.5139\n",
            "Época [820/1000], Loss (treinamento): 0.5138\n",
            "Época [830/1000], Loss (treinamento): 0.5138\n",
            "Época [840/1000], Loss (treinamento): 0.5137\n",
            "Época [850/1000], Loss (treinamento): 0.5136\n",
            "Época [860/1000], Loss (treinamento): 0.5136\n",
            "Época [870/1000], Loss (treinamento): 0.5135\n",
            "Época [880/1000], Loss (treinamento): 0.5134\n",
            "Época [890/1000], Loss (treinamento): 0.5134\n",
            "Época [900/1000], Loss (treinamento): 0.5133\n",
            "Época [900/1000], Acurácia (teste): 76.67%\n",
            "Época [910/1000], Loss (treinamento): 0.5132\n",
            "Época [920/1000], Loss (treinamento): 0.5132\n",
            "Época [930/1000], Loss (treinamento): 0.5131\n",
            "Época [940/1000], Loss (treinamento): 0.5130\n",
            "Época [950/1000], Loss (treinamento): 0.5130\n",
            "Época [960/1000], Loss (treinamento): 0.5129\n",
            "Época [970/1000], Loss (treinamento): 0.5128\n",
            "Época [980/1000], Loss (treinamento): 0.5128\n",
            "Época [990/1000], Loss (treinamento): 0.5127\n",
            "Época [1000/1000], Loss (treinamento): 0.5127\n",
            "Época [1000/1000], Acurácia (teste): 76.67%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'losses' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2289953836.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Plot 1: Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Loss (treinamento)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Evolução da Loss durante o Treinamento'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Épocas'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}